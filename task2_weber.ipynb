{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_df.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scenario'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose each simulation run has a result of accident/non-accident, calculate the \n",
    "probability of accident (counts, marginal probability). Hint: for each run, the \n",
    "collision results are stored in ‘route_highway.txt’. You can check the accident \n",
    "status by looking at the ‘status’ field under the ‘record’ section (‘Completed’ means \n",
    "no accident; ‘Failed’ means an accident has occurred). (1 point) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_status = df.groupby('scenario')['status'].nunique()\n",
    "scenario_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = df.drop_duplicates(subset=[\"scenario\"]).shape[0]\n",
    "accident_runs = df[df['status'] == 'Failed'].drop_duplicates(subset=[\"scenario\"]).shape[0]\n",
    "print(f\"Total number of distinct simulation runs: {total_runs}\")\n",
    "print(f\"Number of accident runs: {accident_runs}\")\n",
    "accident_probability = accident_runs / total_runs\n",
    "print(f\"Accident probability: {accident_probability:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. By looking at the completion records and the plots you generated in Task 1, under\n",
    "- which weather condition(s) did the accident happen?\n",
    "- Does that match your guess in Task 1?\n",
    "- When did the accident happen during those simulation runs?\n",
    "- Why do you think the accident happened at that instance? Discuss each accident case separately. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_noon_df = df[df['scenario']=='rain-noon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_noon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_brake_data = rain_noon_df[rain_noon_df['brake'] == 1]\n",
    "accident_brake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4224:4240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "features = ['throttle', 'steer', 'brake', 'cvip', 'x', 'y', 'v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized_ts'] = df.groupby('scenario')['ts'].transform(lambda x: x - x.min())\n",
    "\n",
    "# Create a plot for each feature with 'normalized_ts' as the x-axis and different scenarios as different lines\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot each scenario as a line\n",
    "    for scenario in df['scenario'].unique():\n",
    "        scenario_data = df[df['scenario'] == scenario]\n",
    "        plt.plot(scenario_data['normalized_ts'], scenario_data[feature], label=scenario)\n",
    "    plt.title(f'{feature} Over Normalized Time for Different Scenarios')\n",
    "    plt.xlabel('Normalized Timestamp')\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend(title='Scenario')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the plot to normalized time greater than 10 seconds\n",
    "feature = 'cvip'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot each scenario as a line, restricting to normalized_ts > 10\n",
    "for scenario in df['scenario'].unique():\n",
    "    scenario_data = df[(df['scenario'] == scenario) & (df['normalized_ts'] > 10)]\n",
    "    plt.plot(scenario_data['normalized_ts'], scenario_data[feature], label=scenario)\n",
    "\n",
    "plt.title(f'{feature} Over Normalized Time (After 10 seconds) for Different Scenarios')\n",
    "plt.xlabel('Normalized Timestamp')\n",
    "plt.ylabel(feature)\n",
    "plt.legend(title='Scenario')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the plot to normalized time between 350 and 450 seconds\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot each scenario as a line, restricting to normalized_ts between 350 and 450\n",
    "    for scenario in df['scenario'].unique():\n",
    "        scenario_data = df[(df['scenario'] == scenario) &\n",
    "                                    (df['normalized_ts'] >= 360) &\n",
    "                                    (df['normalized_ts'] <= 450)]\n",
    "        plt.plot(scenario_data['normalized_ts'], scenario_data[feature], label=scenario)\n",
    "    plt.title(f'{feature} Over Normalized Time (350-450 seconds) for Different Scenarios')\n",
    "    plt.xlabel('Normalized Timestamp')\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend(title='Scenario')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_scenarios = ['clear-noon', 'clear-sunset', 'rain-noon']\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot each selected scenario as a line, restricting to normalized_ts between 350 and 450\n",
    "    for scenario in selected_scenarios:\n",
    "        scenario_data = df[(df['scenario'] == scenario) &\n",
    "                                    (df['normalized_ts'] >= 360) &\n",
    "                                    (df['normalized_ts'] <= 450)]\n",
    "        plt.plot(scenario_data['normalized_ts'], scenario_data[feature], label=scenario)\n",
    "    \n",
    "    plt.title(f'{feature} Over Normalized Time (360-450 seconds) for Selected Scenarios')\n",
    "    plt.xlabel('Normalized Timestamp')\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend(title='Scenario')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
